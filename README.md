# ComputerVision-HandSign_Detection
American Sign Language (ASL) is a complete, natural language that has the same linguistic properties as spoken languages, with grammar that differs from English. ASL is expressed by movements of the hands and face. It is the primary language of many North Americans who are deaf and hard of hearing and is used by some hearing people as well.

There have been several advancements in technology and a lot of research has been done to help the people who are deaf and dumb. Aiding the cause, Deep learning, and computer vision can be used too to make an impact on this cause.
This can be very helpful for the deaf and dumb people in communicating with others as knowing sign language is not something that is common to all, moreover, this can be extended to creating automatic editors, where the person can easily write by just their hand gestures.

This Computer Vision project is based on detecting the alphabets made by hand movements with the help of OpenCV and TensorFlow Python packages. 
In the first part, data is collected by hand movements and stored in the computer which is required to train the model.
In the second part, Google's Teachable Machine is used to build the model and model is therefore run live to detect the hand movements.
